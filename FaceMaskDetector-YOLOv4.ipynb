{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MQlb3PZq8O5I"
   },
   "source": [
    "<p><a href=\"https://opencv.org/courses/\"><img alt=\"OpenCV logo\" height=\"45px\" src=\"https://opencv.org/wp-content/uploads/2020/07/cropped-OpenCV_logo_white.png\" align=\"left\" style=\"width:80px;height:80px;\"></a></p>   <h1>Computer Vision II: Applications (Python)</h1>  \n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](FaceMaskDetector-YOLOv4.ipynb)\n",
    "\n",
    "<h2>Project 3: Train a Face Mask Detector<h2>\n",
    "    \n",
    "PART 2/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4k5L00Task2q"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Train the object detector using YOLO v4 to recognize masks covering a human face.\n",
    "\n",
    "YOLO &#8594; You Only Look Once  \n",
    "\n",
    "Use this [HOWTO](https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects) as a reference for training your model using YOLO v4 architecture and pre-trained model.\n",
    "\n",
    "https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1L69Cw_tnj8b"
   },
   "source": [
    "# Notebook preparation\n",
    "\n",
    "Review the following variable before starting this notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zj0JSbMyuzZ3"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "# -------\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import io, shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "#from ipythonblocks import ImageGrid, BlockGrid, colors\n",
    "from google.colab import files, drive\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f1fS4QcTfHA4"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (15.0,15.0)\n",
    "#matplotlib.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGCpiO0Os8a_"
   },
   "source": [
    "This is the part of the code that you may want to modify. Check where you want to run **darknet** framework.  \n",
    "It is recommended to run in persistent storage such as *Google Drive* to avoiding lost tem ongoing working in case of a *Kernel disconnect*.  \n",
    "<BR>\n",
    "Please, check the Combo Box below to load the **darknet** framework and **dataset** into your *Google Drive*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nhg9bA0wnchU"
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "# ----------- #\n",
    "# Change HERE #\n",
    "# ----------- #\n",
    "USE_GOOGLE_DRIVE = True #@param {type:\"boolean\"}\n",
    "google_drive_base_dir = '/content/drive/My Drive/' if USE_GOOGLE_DRIVE else '/tmp/'\n",
    "darknet_drive = google_drive_base_dir + 'darknet/'\n",
    "dataset_drive = google_drive_base_dir + 'dataset/'\n",
    "test_ds_drive = dataset_drive + 'test/'           \n",
    "training_ds_drive = dataset_drive + 'training/'   \n",
    "# ----------- #\n",
    "#  END        #\n",
    "# ----------- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "elTtEPrsZKbv"
   },
   "source": [
    "Based on the directories defined above, the tree to compute the face mask detection will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "tpOX87WHyo39",
    "outputId": "a0cd3810-4b4e-4f2a-c1b3-6093492bde44"
   },
   "outputs": [],
   "source": [
    "base_path = Path(google_drive_base_dir)\n",
    "darknet_path = Path(darknet_drive)\n",
    "dataset_path = Path(dataset_drive)\n",
    "test_ds_path = Path(test_ds_drive)\n",
    "train_ds_path = Path(training_ds_drive)\n",
    "\n",
    "print('-- Working Directories --')\n",
    "print(f'* BASE   : {base_path.as_posix()}')\n",
    "print(f'* DARKNET: {darknet_path.as_posix()}')\n",
    "print('\\nDATASE :')\n",
    "print(f'* TEST   : {test_ds_path.as_posix()}')\n",
    "print(f'* TRAIN  : {train_ds_path.as_posix()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hUY_cbxT8O5S"
   },
   "outputs": [],
   "source": [
    "# Test data\n",
    "test_images = [(test_ds_path.as_posix()+'/test-image1.jpg',\n",
    "                'https://www.dropbox.com/s/fxei8rit9v2n83s/test-image1.jpg?dl=1'),\n",
    "               (test_ds_path.as_posix()+'/test-image2.jpg',\n",
    "                'https://www.dropbox.com/s/ia1fijzr69ytpp1/test-image2.jpg?dl=1'),\n",
    "               (test_ds_path.as_posix()+'/test-image3.jpg',\n",
    "                'https://www.dropbox.com/s/g905k4r1git5kbx/test-image3.jpg?dl=1'),\n",
    "               (test_ds_path.as_posix()+'/test-image4.jpg',\n",
    "                'https://www.dropbox.com/s/90ggmiur7b8g35m/test-image4.jpg?dl=1')]\n",
    "test_videos = [(test_ds_path.as_posix()+'/test-video1.mp4',\n",
    "                'https://www.dropbox.com/s/pds0w3z5y7w89oz/test-video1.mp4?dl=1'),\n",
    "               (test_ds_path.as_posix()+'/test-video2.mp4',\n",
    "                'https://www.dropbox.com/s/sqwu0ktdtlxtdsd/test-video2.mp4?dl=1')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JtdA-ur7mXmj"
   },
   "source": [
    "Working from a persistent environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "colab_type": "code",
    "id": "7PCoBErzi_mp",
    "outputId": "ba5b4564-de18-4d31-a2c1-9d526139df03"
   },
   "outputs": [],
   "source": [
    "if USE_GOOGLE_DRIVE:\n",
    "  drive.mount('/content/drive')\n",
    "  %cd {google_drive_base_dir}\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eMGRcK59rZ9a"
   },
   "source": [
    "If you don't want to wipe out the darknet directory from your Google drive, skip the following line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f692vgKnm6Hr"
   },
   "outputs": [],
   "source": [
    "DELETE_DARKNET = False #@param {type:\"boolean\"}\n",
    "if DELETE_DARKNET:\n",
    "  print(f'Deleting {darknet_path}')\n",
    "  darknet_path.rmdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jghFBXZZiD3Q"
   },
   "source": [
    "## Installing required softwares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8vcKq33Yue8i"
   },
   "source": [
    "From pip source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IbaxbRyOQCpq"
   },
   "outputs": [],
   "source": [
    "# not in use yet\n",
    "#!pip install -q ipythonblocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YfBosTO6ienP"
   },
   "source": [
    "# DarkNet\n",
    "\n",
    "You can skip this section if you already have **darknet** installed and built in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5YTtWDmGukPK"
   },
   "source": [
    "## Clone from Github\n",
    "\n",
    "Clone **darknet** from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "7PgcZmR7urmW",
    "outputId": "3e2a7ff6-6f2d-42fe-8714-52dc16d8410a"
   },
   "outputs": [],
   "source": [
    "print('Downloading darknet to ' + darknet_drive)\n",
    "!git clone https://github.com/AlexeyAB/darknet.git '{darknet_drive}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-v99ux5ZwUWF"
   },
   "source": [
    "## Compile DarkNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "JI7gJm14iNZO",
    "outputId": "c1f85f19-f74d-4872-f729-1fe20bdae955"
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$darknet_drive\"\n",
    "DARKNETDIR=$1\n",
    "cd \"$DARKNETDIR\"\n",
    "pwd\n",
    "\n",
    "sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
    "sed -i 's/GPU=0/GPU=1/' Makefile\n",
    "sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
    "\n",
    "echo \"Building. . . It might take 2 minutes\"\n",
    "\n",
    "make &> build_log.txt\n",
    "\n",
    "echo \"Build completed, CONGRATS!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "k9l0-KOUZNUC",
    "outputId": "88392062-6271-4822-fff2-5ac7ce833e2b"
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$darknet_drive\"\n",
    "DARKNETDIR=$1\n",
    "cd \"$DARKNETDIR\"\n",
    "chmod u+x ./darknet\n",
    "ls -l darknet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koBIxzuqi2WT"
   },
   "source": [
    "# YOLOv4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OjGX08T4u44m"
   },
   "source": [
    "## Download YOLO v4 weights\n",
    "\n",
    "For training cfg/yolov4-custom.cfg download the pre-trained weights-file (162 MB): [yolov4.conv.137](https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137) (Google drive mirror [yolov4.conv.137](https://drive.google.com/open?id=1JKF-bdIklxOOVy-2Cr5qdvjgGpmGfcbp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "LqxHq7iQi7HP",
    "outputId": "bb79f65d-2f37-41fa-eee8-5a8c4e4cc629"
   },
   "outputs": [],
   "source": [
    "yolov4_weights = darknet_drive+'/yolov4.weights'\n",
    "yolov4_weights_path = Path(yolov4_weights)\n",
    "\n",
    "if yolov4_weights_path.exists():\n",
    "    print('The YOLOv4 custom config has found in your darknet framework!')\n",
    "else:\n",
    "    !wget \"https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137\" \\\n",
    "    -O \"{yolov4_weights_path.as_posix()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare YOLO v4 custom configuration file  \n",
    "\n",
    "Create file yolo-face.cfg with the same content as in yolov4-custom.cfg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov4_custom_cfg = darknet_drive+'/cfg/yolov4-custom.cfg'\n",
    "yolov4_mask_train_cfg = darknet_drive+'/cfg/yolov4-mask-train.cfg'\n",
    "\n",
    "darknet_yolov4_custom_cfg_path = Path(yolov4_custom_cfg)\n",
    "darknet_yolov4_mask_train_cfg_path = Path(yolov4_mask_train_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify on *yolov4-obj.cfg* file:\n",
    "* change line *batch* to ```batch=64```\n",
    "* change line *subdivisions* to ```subdivisions=16```\n",
    "* change line *max_batches* to ```max_batches = 6000```\n",
    "* change line *steps* to ```steps=4800,5400```\n",
    "* set network size (*width* and *height*) to ```width=416``` and ```height=416```\n",
    "* change line *classes* to ```classes=2``` in each of 3 **[yolo]** layers\n",
    "* change line *filters* to ```filters=21``` in the 3 **[convolutional]** layer before each **[yolo]** layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z5mffpGHIV60",
    "outputId": "7c401b56-1a26-4215-abc4-f800c61499b3"
   },
   "outputs": [],
   "source": [
    "yolov4_mask_train_cfg = \"\"\"[net]\n",
    "# Testing\n",
    "#batch=1\n",
    "#subdivisions=1\n",
    "# Training\n",
    "batch=64\n",
    "subdivisions=16\n",
    "width=608\n",
    "height=608\n",
    "channels=3\n",
    "momentum=0.949\n",
    "decay=0.0005\n",
    "angle=0\n",
    "saturation = 1.5\n",
    "exposure = 1.5\n",
    "hue=.1\n",
    "\n",
    "learning_rate=0.001\n",
    "burn_in=1000\n",
    "max_batches = 500500\n",
    "policy=steps\n",
    "steps=400000,450000\n",
    "scales=.1,.1\n",
    "\n",
    "#cutmix=1\n",
    "mosaic=1\n",
    "\n",
    "#:104x104 54:52x52 85:26x26 104:13x13 for 416\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=32\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "# Downsample\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[route]\n",
    "layers = -2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=32\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[route]\n",
    "layers = -1,-7\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "# Downsample\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[route]\n",
    "layers = -2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[route]\n",
    "layers = -1,-10\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "# Downsample\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[route]\n",
    "layers = -2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[route]\n",
    "layers = -1,-28\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "# Downsample\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[route]\n",
    "layers = -2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[route]\n",
    "layers = -1,-28\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "# Downsample\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=1024\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[route]\n",
    "layers = -2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "\n",
    "[route]\n",
    "layers = -1,-16\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=1024\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=mish\n",
    "stopbackward=800\n",
    "\n",
    "##########################\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=1024\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "### SPP ###\n",
    "[maxpool]\n",
    "stride=1\n",
    "size=5\n",
    "\n",
    "[route]\n",
    "layers=-2\n",
    "\n",
    "[maxpool]\n",
    "stride=1\n",
    "size=9\n",
    "\n",
    "[route]\n",
    "layers=-4\n",
    "\n",
    "[maxpool]\n",
    "stride=1\n",
    "size=13\n",
    "\n",
    "[route]\n",
    "layers=-1,-3,-5,-6\n",
    "### End SPP ###\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=1024\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[upsample]\n",
    "stride=2\n",
    "\n",
    "[route]\n",
    "layers = 85\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[route]\n",
    "layers = -1, -3\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=512\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=512\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[upsample]\n",
    "stride=2\n",
    "\n",
    "[route]\n",
    "layers = 54\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[route]\n",
    "layers = -1, -3\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=256\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=256\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "##########################\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=256\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "filters=255\n",
    "activation=linear\n",
    "\n",
    "\n",
    "[yolo]\n",
    "mask = 0,1,2\n",
    "anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401\n",
    "classes=80\n",
    "num=9\n",
    "jitter=.3\n",
    "ignore_thresh = .7\n",
    "truth_thresh = 1\n",
    "scale_x_y = 1.2\n",
    "iou_thresh=0.213\n",
    "cls_normalizer=1.0\n",
    "iou_normalizer=0.07\n",
    "iou_loss=ciou\n",
    "nms_kind=greedynms\n",
    "beta_nms=0.6\n",
    "max_delta=5\n",
    "\n",
    "\n",
    "[route]\n",
    "layers = -4\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "filters=256\n",
    "activation=leaky\n",
    "\n",
    "[route]\n",
    "layers = -1, -16\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=512\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=512\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=512\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "filters=255\n",
    "activation=linear\n",
    "\n",
    "\n",
    "[yolo]\n",
    "mask = 3,4,5\n",
    "anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401\n",
    "classes=80\n",
    "num=9\n",
    "jitter=.3\n",
    "ignore_thresh = .7\n",
    "truth_thresh = 1\n",
    "scale_x_y = 1.1\n",
    "iou_thresh=0.213\n",
    "cls_normalizer=1.0\n",
    "iou_normalizer=0.07\n",
    "iou_loss=ciou\n",
    "nms_kind=greedynms\n",
    "beta_nms=0.6\n",
    "max_delta=5\n",
    "\n",
    "\n",
    "[route]\n",
    "layers = -4\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "filters=512\n",
    "activation=leaky\n",
    "\n",
    "[route]\n",
    "layers = -1, -37\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=1024\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=1024\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=1024\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "filters=255\n",
    "activation=linear\n",
    "\n",
    "\n",
    "[yolo]\n",
    "mask = 6,7,8\n",
    "anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401\n",
    "classes=80\n",
    "num=9\n",
    "jitter=.3\n",
    "ignore_thresh = .7\n",
    "truth_thresh = 1\n",
    "random=1\n",
    "scale_x_y = 1.05\n",
    "iou_thresh=0.213\n",
    "cls_normalizer=1.0\n",
    "iou_normalizer=0.07\n",
    "iou_loss=ciou\n",
    "nms_kind=greedynms\n",
    "beta_nms=0.6\n",
    "max_delta=5\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Add YOLO v4 config file for test samples {darknet_yolov4_mask_train_cfg_path.as_posix()}\")\n",
    "with open(darknet_yolov4_mask_train_cfg_path.as_posix(), 'wt') as f:\n",
    "  f.write(yolov4_mask_train_cfg)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4-HPrVSeIipE",
    "outputId": "2470b5e5-a2a1-4e9a-e736-6a65b45f957b"
   },
   "outputs": [],
   "source": [
    "yolov_mask_test_cfg = \"\"\"\n",
    "# Based on cfg/yolov3-voc.cfg\n",
    "\n",
    "[net]\n",
    "# Testing\n",
    "batch=1\n",
    "subdivisions=1\n",
    "# Training\n",
    "# batch=64\n",
    "# subdivisions=16\n",
    "width=416\n",
    "height=416\n",
    "channels=3\n",
    "momentum=0.9\n",
    "decay=0.0005\n",
    "angle=0\n",
    "saturation = 1.5\n",
    "exposure = 1.5\n",
    "hue=.1\n",
    "\n",
    "learning_rate=0.001\n",
    "burn_in=400\n",
    "max_batches=5000\n",
    "policy=steps\n",
    "steps=3500\n",
    "scales=.1\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=32\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "# Downsample\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=32\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "# Downsample\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "# Downsample\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "# Downsample\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "# Downsample\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=1024\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=1024\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=1024\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=1024\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=1024\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "######################\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=1024\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=1024\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=1024\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "filters=21\n",
    "activation=linear\n",
    "\n",
    "[yolo]\n",
    "mask = 6,7,8\n",
    "anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
    "classes=2\n",
    "num=9\n",
    "jitter=.3\n",
    "ignore_thresh = .5\n",
    "truth_thresh = 1\n",
    "random=1\n",
    "\n",
    "[route]\n",
    "layers = -4\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[upsample]\n",
    "stride=2\n",
    "\n",
    "[route]\n",
    "layers = -1, 61\n",
    "\n",
    "\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=512\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=512\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=512\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "filters=21\n",
    "activation=linear\n",
    "\n",
    "[yolo]\n",
    "mask = 3,4,5\n",
    "anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
    "classes=2\n",
    "num=9\n",
    "jitter=.3\n",
    "ignore_thresh = .5\n",
    "truth_thresh = 1\n",
    "random=1\n",
    "\n",
    "[route]\n",
    "layers = -4\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[upsample]\n",
    "stride=4\n",
    "\n",
    "[route]\n",
    "layers = -1, 11\n",
    "\n",
    "\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=256\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=256\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=256\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "filters=21\n",
    "activation=linear\n",
    "\n",
    "[yolo]\n",
    "mask = 0,1,2\n",
    "anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
    "classes=2\n",
    "num=9\n",
    "jitter=.3\n",
    "ignore_thresh = .5\n",
    "truth_thresh = 1\n",
    "random=1\n",
    "\"\"\"\n",
    "\n",
    "darnet_yolov_mask_test_cfg = darknet_path.as_posix() + '/yolov3-mask-test.cfg'\n",
    "print(f\"Add YOLO v3 config file for test samples {darnet_yolov_mask_test_cfg}\")\n",
    "with open(darnet_yolov_mask_test_cfg, 'wt') as f:\n",
    "  f.write(yolov_mask_test_cfg)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "temFuFhkwZro",
    "outputId": "ce91fb6e-adee-4fd2-9a77-cb536f765621"
   },
   "outputs": [],
   "source": [
    "yolov4_mask_setup_data = \"\"\"classes=2\n",
    "train  = data_train.txt\n",
    "valid = data_test.txt\n",
    "names = class.names\n",
    "backup = backup/\n",
    "\"\"\"\n",
    "class_names=\"Mask\\nNO_Mask\"\n",
    "\n",
    "darnet_setup_fname = darknet_path.as_posix() + '/yolov4-mask-setup.data'\n",
    "print(f\"Add darknet's setup file {darnet_setup_fname}\")\n",
    "with open(darnet_setup_fname, 'wt') as f:\n",
    "  f.write(yolov4_mask_setup_data)\n",
    "\n",
    "darnet_class_fname = darknet_path.as_posix() + '/class.names'\n",
    "print(f\"Add darknet's class.names file {darnet_class_fname}\")\n",
    "with open(darnet_class_fname, 'wt') as f:\n",
    "  f.write(class_names)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "862sXukhSXlh"
   },
   "outputs": [],
   "source": [
    "yolo_shape = (448,448,3)\n",
    "s = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iLxSiHDUxkHz"
   },
   "source": [
    "# Datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IPk5asozJ8sG"
   },
   "source": [
    "## Training dataset\n",
    "\n",
    "Downloading training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "yuV02jcY4JOz",
    "outputId": "145cb701-2711-4d57-8b90-ea70b1b30b81"
   },
   "outputs": [],
   "source": [
    "if not dataset_path.exists():\n",
    "  print('Adding dir ' + dataset_path.as_posix())\n",
    "  dataset_path.mkdir(parents=True)\n",
    "\n",
    "if not test_ds_path.exists():\n",
    "  print('Adding dir ' + test_ds_path.as_posix())\n",
    "  test_ds_path.mkdir(parents=True)\n",
    "\n",
    "if not train_ds_path.exists():\n",
    "  print('Adding dir ' + train_ds_path.as_posix())\n",
    "  train_ds_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RajK37MzKD64",
    "outputId": "2c10b121-8f6f-4704-c4fa-ff3ac8b9ee82"
   },
   "outputs": [],
   "source": [
    "# ------- #\n",
    "# DATASET #\n",
    "# ------- #\n",
    "dataset_file = train_ds_path.as_posix() + '/kaggle_and_no-mask_dataset.zip'\n",
    "print('Dataset will be downloaded to ' + dataset_file)\n",
    "!wget https://www.dropbox.com/s/6gewe947ake1g95/kaggle_and_no-mask_dataset.zip?dl=1 --output-document \"{dataset_file}\" --quiet\n",
    "!unzip -qo \"{dataset_file}\" -d \"{train_ds_path.as_posix()}\"\n",
    "!rm -v \"{dataset_file}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nW_dJi26MbVA"
   },
   "source": [
    "Creating the darknet config files based on training/validation files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDuTYJkEMidh"
   },
   "outputs": [],
   "source": [
    "def DataSetSplit(path='.', test_size=0.20, random_state=101):\n",
    "    assert test_size < 1.0, \"Test size must be lower than 1.0\"\n",
    "    path_dataset = Path(path)\n",
    "    # every dataset element has a txt and a jpeg file.\n",
    "    # from every txt file, find its jpeg sibling\n",
    "    train_files = []\n",
    "    test_files = []\n",
    "\n",
    "    if not path_dataset.is_dir():\n",
    "        return None, None\n",
    "\n",
    "    # ignoring checking if there is a valid image file for each txt file\n",
    "    all_txt = list(path_dataset.glob('*.txt'))\n",
    "\n",
    "    test_set = int(len(all_txt) * test_size)\n",
    "\n",
    "    random.seed(random_state)\n",
    "    test_population = random.sample(range(len(all_txt)),test_set)\n",
    "\n",
    "    for p in range(len(all_txt)):\n",
    "        if p in test_population:\n",
    "            test_files.append(all_txt[p])\n",
    "        else:\n",
    "            train_files.append(all_txt[p])\n",
    "\n",
    "    return (train_files, test_files)\n",
    "\n",
    "def DarknetGenTrainTest(train,test):\n",
    "    def copy2file(outfname, test_set):\n",
    "        with open(outfname, 'wt') as f:\n",
    "            for t in test_set:\n",
    "                t_path = Path(t)\n",
    "                ppath = t_path.parent\n",
    "                fname = t_path.stem\n",
    "                im_fname = [ i.as_posix()  for i in list(ppath.glob(fname+'*')) if not i.match('*.txt') ]\n",
    "                if len(im_fname) > 0:\n",
    "                    f.write(im_fname[0] + '\\n')\n",
    "\n",
    "    data_train_fname = darknet_path.as_posix() + '/data_train.txt'\n",
    "    data_test_fname = darknet_path.as_posix() + '/data_test.txt'\n",
    "    print(f'Preparing {data_train_fname}')\n",
    "    copy2file(data_train_fname, train)\n",
    "    print(f'Preparing {data_test_fname}')\n",
    "    copy2file(data_test_fname, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "AA_JEqQANPMX",
    "outputId": "c58dbc04-eeba-458e-f933-f316d77b3450"
   },
   "outputs": [],
   "source": [
    "train,test = DataSetSplit(train_ds_path.as_posix())\n",
    "DarknetGenTrainTest(train,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5oaV7VVGJ2jq"
   },
   "source": [
    "## Test Images and Videos\n",
    "\n",
    "Downloading test images and videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "W3OXgeHcUKS_",
    "outputId": "8c33954d-ec68-43c8-8695-56c1a93917ba"
   },
   "outputs": [],
   "source": [
    "for t_file in test_images + test_videos:\n",
    "  print(f'Downloading {t_file[1]} -> {t_file[0]}')\n",
    "  !wget {t_file[1]} --output-document \"{t_file[0]}\" --no-verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "drUPecyOv72q"
   },
   "source": [
    "## Exploring Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "Qph5dG6DIAPX",
    "outputId": "eb6c4072-168a-4c0f-9bbd-c4f3d7ee0f9b"
   },
   "outputs": [],
   "source": [
    "!ls -Gg \"{test_ds_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "n2m7QH8nPgE_",
    "outputId": "8cf8070f-02c5-4975-a93f-317bce7d71d2"
   },
   "outputs": [],
   "source": [
    "w,h = yolo_shape[:2]\n",
    "test_im_fname = test_images[0][0]\n",
    "print(f'Reading image {test_im_fname}')\n",
    "#im_test = Image.open(test_images[0][0]).getdata()\n",
    "im_test = cv.imread(test_im_fname, cv.IMREAD_UNCHANGED)\n",
    "im_test = cv.resize(im_test, yolo_shape[:2], interpolation=cv.INTER_NEAREST)\n",
    "#rows,cols = im_test.shape\n",
    "\n",
    "im_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mo2SE11OP1WA"
   },
   "outputs": [],
   "source": [
    "def show_imcv(im, figsize=(6,6)):\n",
    "  im2show = cv.cvtColor(im, cv.COLOR_BGR2RGB)\n",
    "  plt.figure(figsize=(6,6));\n",
    "  plt.imshow(im2show);\n",
    "  plt.axis('off');\n",
    "  plt.show()\n",
    "  return plt.figure()\n",
    "\n",
    "def show_grid(im_grid, figsize=(6,6)):\n",
    "  r,c = im_grid.shape[:2]\n",
    "  fig = plt.figure(figsize=figsize)\n",
    "  count = 1\n",
    "  for im_line in im_grid:\n",
    "    for im in im_line:\n",
    "      im2 = cv.cvtColor(im, cv.COLOR_BGR2RGB)\n",
    "      fig.add_subplot(r, c, count);\n",
    "      plt.axis('off');\n",
    "      plt.imshow(im2);\n",
    "      count += 1\n",
    "  plt.show()\n",
    "  #return plt.figure()\n",
    "  return fig\n",
    "\n",
    "def grid_cell(im, shape=(7,7)):\n",
    "  shape_v,shape_h = shape\n",
    "  im_hgrids = np.array(np.vsplit(im,shape_v))\n",
    "  im_grids = [ np.hsplit(i, shape_h) for i in im_hgrids ]\n",
    "  return np.array(im_grids)\n",
    "\n",
    "def plot_grid(im, shape, figsize=(6,6)):\n",
    "  '''Plot the image in grid following the suggested shape'''\n",
    "  im_grid = grid_cell(im, shape)\n",
    "  fig = show_grid(im_grid, figsize)\n",
    "  return im_grid,fig\n",
    "\n",
    "def plot_side(im_list, axis='off', figsize=(6,6)):\n",
    "  fig = plt.figure(figsize=figsize)\n",
    "  for i,im in enumerate(im_list, start=1):\n",
    "    im2 = cv.cvtColor(im, cv.COLOR_BGR2RGB)\n",
    "    fig.add_subplot(1,len(im_list),i)\n",
    "    plt.axis(axis);\n",
    "    plt.imshow(im2);\n",
    "  plt.show()\n",
    "\n",
    "def convert_pltfig_in_img(plt_fig, size=None):\n",
    "  # https://stackoverflow.com/questions/7821518/matplotlib-save-plot-to-numpy-array\n",
    "  buf_ = io.BytesIO()\n",
    "  plt_fig.show()\n",
    "  plt_fig.savefig(buf_, format='png', dpi='figure')\n",
    "  buf_.seek(0)\n",
    "  im_arr = np.frombuffer(buf_.getvalue(), dtype=np.uint8)\n",
    "  buf_.close()\n",
    "  im = cv.imdecode(im_arr, cv.IMREAD_UNCHANGED)\n",
    "  if type(size) is tuple:\n",
    "    im = cv.resize(im, size, interpolation=cv.INTER_NEAREST)\n",
    "  return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "MZm6Yzc1eQOR",
    "outputId": "b608dc98-2fa4-4191-fc78-562fbcfee345"
   },
   "outputs": [],
   "source": [
    "#block_size=w//s\n",
    "plt_fig = show_imcv(im_test)\n",
    "plt_fig.savefig('test.png', format='png', dpi='figure');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "73Ty4GkPzm90",
    "outputId": "57c37b97-1232-4db9-d410-f062044cbd33"
   },
   "outputs": [],
   "source": [
    "im_grid,plt_fig = plot_grid(im_test, shape=(s,s))\n",
    "plt_fig.savefig('test_grid.png', format='png', dpi='figure');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "3iR6ljpbP_O6",
    "outputId": "e368041b-0fce-40f7-eed7-27703478ae7e"
   },
   "outputs": [],
   "source": [
    "files.download('test_grid.png')\n",
    "files.download('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oEJjbmywAOm6"
   },
   "outputs": [],
   "source": [
    "im_fig = convert_pltfig_in_img(plt_fig, im_test.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "colab_type": "code",
    "id": "OR7PdG9J2cEB",
    "outputId": "a469d393-3c51-4956-eeba-f62c89b26eff"
   },
   "outputs": [],
   "source": [
    "plot_side([im_test, im_fig], figsize=(12,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5az87V5wfQuy"
   },
   "source": [
    "# Train Model\n",
    "\n",
    "## Training Configuration  \n",
    "\n",
    "```bash\n",
    "$ ./darknet detector train \\\n",
    "yolov3-face-setup.data \\\n",
    "yolov3-face-train.cfg \\\n",
    "./darknet53.conv.74 \\\n",
    "-dont_show -map 2> train_log.txt\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "OfLc3H7OGue7",
    "outputId": "6b3ba65d-0757-47e8-ec26-12bacf8c03c6"
   },
   "outputs": [],
   "source": [
    "print(f'Moving do {darknet_path.as_posix()}')\n",
    "%cd {darknet_path.as_posix()}\n",
    "!ls -Gg yolov3-mask*\n",
    "!ls -Gg yolov3.weights\n",
    "!ls -Gg class.names\n",
    "!ls -Gg data_*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XwZutkNJNnGv",
    "outputId": "8a164048-74c5-4a05-d050-f61665bac2b0"
   },
   "outputs": [],
   "source": [
    "!./darknet detector train \\\n",
    "yolov3-mask-setup.data \\\n",
    "yolov3-mask-train.cfg \\\n",
    "yolov3.weights \\\n",
    "-dont_show -map -clear 2> train_log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7KHHT-dBjtXA",
    "outputId": "ee938092-3eef-487e-f498-2a817bb38381"
   },
   "outputs": [],
   "source": [
    "!ls -ltr ./backup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O-wN5H4YAaoG"
   },
   "source": [
    "# Inference\n",
    "\n",
    "## Inference command example  \n",
    "\n",
    "```bash\n",
    "$ !./darknet detect cfg/yolov3.cfg yolov3.weights traffic.jpg -thresh 0.5\n",
    "```\n",
    "\n",
    "## Demo\n",
    "\n",
    "```bash\n",
    "$ !./darknet detector demo yolo_mask.data yolo_mask.cfg backup/yolo_mask_best.weights test-video1.mp4 -thresh .6 -out_filename out-vid1.avi -dont_show\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "SRRFm1PMAkWD",
    "outputId": "ee384e72-664c-43a9-fa50-830b9fcfdcbf"
   },
   "outputs": [],
   "source": [
    "im_fname = test_ds_path.as_posix() + '/p-test-image8.jpeg'\n",
    "!pwd\n",
    "!chmod +x darknet\n",
    "!./darknet detector test \\\n",
    "yolov3-mask-setup.data \\\n",
    "yolov3-mask-test.cfg \\\n",
    "backup/yolov3-mask-train_final.weights \\\n",
    "'{im_fname}' \\\n",
    "-thresh 0.6 -dont_show 2> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "PK9X2peci1Gt",
    "outputId": "8f41f66e-356b-400e-e1b3-67c32a2f746e"
   },
   "outputs": [],
   "source": [
    "im_test = cv.imread(im_fname, cv.IMREAD_UNCHANGED)\n",
    "print(im_fname)\n",
    "plt_fig = show_imcv(im_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "e4R8EXcJlDt_",
    "outputId": "11b5b0ff-c6c4-46fb-b5af-8cc5678fc074"
   },
   "outputs": [],
   "source": [
    "im_predict_fname = darknet_path.as_posix() + '/predictions.jpg'\n",
    "im_predict = cv.imread(im_predict_fname, cv.IMREAD_UNCHANGED)\n",
    "print(im_predict_fname)\n",
    "plt_fig = show_imcv(im_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8h5Qu62TkMpR",
    "outputId": "ad6ef7c2-c914-4592-e8a5-227a384a3493"
   },
   "outputs": [],
   "source": [
    "#!./darknet detector demo yolov3-mask-setup.data yolov3-mask-test.cfg backup/yolov3-mask-train_final.weights {test_ds_path.as_posix()}/test-video1.mp4 -thresh .6 -out_filename out-vid1.avi -dont_show\n",
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y4sCq3KmqtP_"
   },
   "source": [
    "# Reference\n",
    "\n",
    "1. YOLO site - [YOLO](https://pjreddie.com/darknet/yolo)  \n",
    "2. [Teste](http://teste.com/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kkysl7ZkrUW0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of FaceMaskDetector-YOLOv3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
